{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "from bmcs_shell.folding.assembly.wb_scanned_cell import WBScannedCell\n",
    "from bmcs_shell.api import WBTessellation4PEx\n",
    "from scipy.spatial import cKDTree\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import k3d\n",
    "import numpy as np\n",
    "from bmcs_shell.folding.assembly.wb_scanned_cell import WBScannedCell\n",
    "from bmcs_shell.api import WBTessellation4PEx\n",
    "from scipy.spatial import cKDTree\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Set the reference geometry to be generated from the closed form kinematics\n",
    "\n",
    "wb_shell = WBTessellation4PEx(\n",
    "                         a=1000/4,\n",
    "                         b = 1615/4, \n",
    "                         c = 645/4, \n",
    "                         e_x = 286/4,\n",
    "                         gamma=0.683, # a value of gamma = 0.75 was estimated from normals, but a CAD comparison showed that 0.75 doesn't lead to closer geometry to the scanned \n",
    "                         n_phi_plus=2, # planned 5 \n",
    "                         n_x_plus=2,  # planned 3\n",
    "                         wireframe_width=5,\n",
    "                        ##---- Trimming function works only in WBTessellation4P ----##\n",
    "                         trim_half_cells_along_y=True,\n",
    "                         trim_half_cells_along_x=True,\n",
    "#                          align_outer_nodes_along_x=True,\n",
    ")\n",
    "# wb_shell.interact()\n",
    "orig_I_Fi = np.copy(wb_shell.I_Fi_trimmed)\n",
    "orig_X_Ia = np.copy(wb_shell.X_Ia_trimmed)\n",
    "\n",
    "# Define the instance cell of the WBScannedCell class\n",
    "\n",
    "modules = {'WB305': ('WB305_facets_points.obj', [[1, 0], [np.pi/2, np.pi/2]]),\n",
    "            'WB306': ('WB306_facets_points.obj', [[1, 0], [np.pi/2, -np.pi/2]]),\n",
    "            'WB307': ('WB307_facets_points.obj', [[1], [np.pi/2]]),\n",
    "            'WB308': ('WB308_facets_points.obj', [[1, 2], [np.pi/2, np.pi]]),\n",
    "            'WB309': ('WB309_facets_points.obj', [[0, 2], [np.pi/2, -np.pi/2]]),\n",
    "            'WB310': ('WB310_facets_points.obj', [[1, 2], [np.pi/2, np.pi]]),\n",
    "            'WB311': ('WB311_facets_points.obj', [[1], [np.pi/2]]),\n",
    "            'WB312': ('WB312_facets_points.obj', [[1], [-np.pi/2]])\n",
    "            }\n",
    "\n",
    "def calculate_normal(vertices):\n",
    "    \"\"\"\n",
    "    Calculate the normal of a triangle or quadrilateral facet.\n",
    "    \"\"\"\n",
    "    if len(vertices) == 3:  # Triangle\n",
    "        v1, v2, v3 = vertices\n",
    "        vec1 = v2 - v1\n",
    "        vec2 = v3 - v1\n",
    "        normal = np.cross(vec1, vec2)\n",
    "    elif len(vertices) == 4:  # Quadrilateral\n",
    "        v1, v2, v3, v4 = vertices\n",
    "        vec1 = v2 - v1\n",
    "        vec2 = v4 - v1\n",
    "        vec3 = v3 - v2\n",
    "        normal1 = np.cross(vec1, vec2)\n",
    "        normal2 = np.cross(vec3, vec1)\n",
    "        normal = (normal1 + normal2) / 2  # Average the normals\n",
    "    else:\n",
    "        raise ValueError(\"Facet must have 3 (triangle) or 4 (quadrilateral) vertices.\")\n",
    "    \n",
    "    return normal / np.linalg.norm(normal)  # Normalize the vector\n",
    "\n",
    "def calculate_angle(normal1, normal2):\n",
    "    \"\"\"\n",
    "    Calculate the angle (in degrees) between two normal vectors.\n",
    "    \"\"\"\n",
    "    cos_theta = np.clip(np.dot(normal1, normal2), -1.0, 1.0)\n",
    "    angle_radians = np.arccos(cos_theta)\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    \n",
    "    # Compute the rotation axis\n",
    "    rotation_axis = np.cross(normal1, normal2)\n",
    "    rotation_direction = {\n",
    "        'x': 'clockwise' if rotation_axis[0] < 0 else 'counterclockwise',\n",
    "        'y': 'clockwise' if rotation_axis[1] < 0 else 'counterclockwise',\n",
    "        'z': 'clockwise' if rotation_axis[2] < 0 else 'counterclockwise'\n",
    "    }\n",
    "    \n",
    "    return angle_degrees, rotation_direction\n",
    "\n",
    "def calculate_normals_and_angle(facets_N_OS, orig_points, scan_points):\n",
    "    # Create a DataFrame to store the results\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(facets_N_OS)):\n",
    "        facet_orig_coord = orig_points[facets_N_OS[i]]\n",
    "        facet_scan_coord = scan_points[facets_N_OS[i]]\n",
    "        \n",
    "        # Calculate normals for original and scanned facets\n",
    "        n_orig = calculate_normal(facet_orig_coord)\n",
    "        n_scan = calculate_normal(facet_scan_coord)\n",
    "        \n",
    "        # Calculate the angle and rotation direction\n",
    "        angle, rotation_direction = calculate_angle(n_orig, n_scan)\n",
    "        \n",
    "        # Add the result to the DataFrame\n",
    "        results.append({\n",
    "            'Facet': i,\n",
    "            'Angle between normals (degrees)': angle\n",
    "        })\n",
    "    \n",
    "    # Create the DataFrame from the results list\n",
    "    df_normals = pd.DataFrame(results)\n",
    "    return df_normals\n",
    "\n",
    "def define_facets():\n",
    "    \"\"\"Define the list with the facet nodes.\"\"\"\n",
    "    return [\n",
    "        [15, 13, 14], [6, 14, 12], [6, 2, 10],\n",
    "        [0, 2, 3, 1], [1, 3, 7], [7, 3, 8],\n",
    "        [8, 9, 10], [10, 12, 11], [7, 11, 5],\n",
    "        [7, 5, 1], [1, 5, 4, 0], [0, 4, 6],\n",
    "        [6, 4, 17], [17, 16, 15]\n",
    "    ]\n",
    "\n",
    "def initialize_kdtree(scan_points):\n",
    "    \"\"\"Initialize a KDTree for the scan points.\"\"\"\n",
    "    return cKDTree(scan_points)\n",
    "\n",
    "def compute_nearest_neighbors(tree, orig_points):\n",
    "    \"\"\"Find the nearest neighbors in the scan for each point in the original geometry.\"\"\"\n",
    "    distances, indices = tree.query(orig_points)\n",
    "    return distances, indices\n",
    "\n",
    "def create_differences_dataframe(orig_points, scan_points, scan_indices, distances):\n",
    "    \"\"\"Create a DataFrame containing differences and distances for points.\"\"\"\n",
    "    diffs = scan_points - orig_points\n",
    "    columns = [\n",
    "        \"orig_index\", \"scan_index\", \"orig_x\", \"orig_y\", \"orig_z\",\n",
    "        \"scan_x\", \"scan_y\", \"scan_z\", \"delta_x\", \"delta_y\", \"delta_z\", \"euclidean_distance\"\n",
    "    ]\n",
    "    df_nodes = pd.DataFrame(columns=columns)\n",
    "    for i in range(len(orig_points)):\n",
    "        df_nodes.loc[i] = [\n",
    "            i,                           # orig_index\n",
    "            scan_indices[i],             # scan_index\n",
    "            *orig_points[i],             # orig_x, orig_y, orig_z\n",
    "            *scan_points[i],             # scan_x, scan_y, scan_z\n",
    "            *diffs[i],                   # delta_x, delta_y, delta_z\n",
    "            distances[i]                 # euclidean_distance\n",
    "        ]\n",
    "    return df_nodes\n",
    "\n",
    "def save_dataframe_to_excel(df, filename):\n",
    "    \"\"\"Save a DataFrame to an Excel file.\"\"\"\n",
    "    df.to_excel(filename, index=False, engine='openpyxl')\n",
    "\n",
    "def compute_statistics(aggregated_data):\n",
    "    \"\"\"Compute statistical metrics for each node.\"\"\"\n",
    "    stats_data = []\n",
    "    for node_index, data in aggregated_data.items():\n",
    "        stats = {\n",
    "            'node_index': node_index,\n",
    "            'mean_delta_x': np.mean(data['delta_x']),\n",
    "            'mean_delta_y': np.mean(data['delta_y']),\n",
    "            'mean_delta_z': np.mean(data['delta_z']),\n",
    "            'mean_distance': np.mean(data['euclidean_distance']),\n",
    "            'std_delta_x': np.std(data['delta_x']),\n",
    "            'std_delta_y': np.std(data['delta_y']),\n",
    "            'std_delta_z': np.std(data['delta_z']),\n",
    "            'std_distance': np.std(data['euclidean_distance']),\n",
    "            'cov_delta_x': np.std(data['delta_x']) / np.mean(data['delta_x']) if np.mean(data['delta_x']) != 0 else 0,\n",
    "            'cov_delta_y': np.std(data['delta_y']) / np.mean(data['delta_y']) if np.mean(data['delta_y']) != 0 else 0,\n",
    "            'cov_delta_z': np.std(data['delta_z']) / np.mean(data['delta_z']) if np.mean(data['delta_z']) != 0 else 0,\n",
    "            'cov_distance': np.std(data['euclidean_distance']) / np.mean(data['euclidean_distance']) if np.mean(data['euclidean_distance']) != 0 else 0,\n",
    "            'quantile_5_delta_x': np.percentile(data['delta_x'], 5),\n",
    "            'quantile_5_delta_y': np.percentile(data['delta_y'], 5),\n",
    "            'quantile_5_delta_z': np.percentile(data['delta_z'], 5),\n",
    "            'quantile_5_distance': np.percentile(data['euclidean_distance'], 5),\n",
    "            'quantile_95_delta_x': np.percentile(data['delta_x'], 95),\n",
    "            'quantile_95_delta_y': np.percentile(data['delta_y'], 95),\n",
    "            'quantile_95_delta_z': np.percentile(data['delta_z'], 95),\n",
    "            'quantile_95_distance': np.percentile(data['euclidean_distance'], 95),\n",
    "        }\n",
    "        stats_data.append(stats)\n",
    "    return pd.DataFrame(stats_data)\n",
    "\n",
    "def calculate_statistics_from_dict(data_dict, key_name):\n",
    "    \"\"\"\n",
    "    Calculate statistics for each entry in a dictionary and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_dict (dict): Dictionary with entries containing lists of numerical values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with statistics (mean, std, 5% quantile, 95% quantile) for each key.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each key-value pair in the dictionary\n",
    "    for key, metrics in data_dict.items():\n",
    "        for metric_name, values in metrics.items():\n",
    "            # Calculate statistics\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            quantile_5_val = np.percentile(values, 5)\n",
    "            quantile_95_val = np.percentile(values, 95)\n",
    "\n",
    "            # Append the results as a dictionary\n",
    "            results.append({\n",
    "                key_name: key,\n",
    "                \"metric\": metric_name,\n",
    "                f\"{metric_name}_mean\": mean_val,\n",
    "                f\"{metric_name}_std\": std_val,\n",
    "                f\"{metric_name}_quantile_5\": quantile_5_val,\n",
    "                f\"{metric_name}_quantile_95\": quantile_95_val,\n",
    "            })\n",
    "\n",
    "    # Convert the results into a DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def calculate_statistics_from_dict(data_dict, key_name):\n",
    "    \"\"\"\n",
    "    Calculate statistics for each entry in a dictionary and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        data_dict (dict): Dictionary with entries containing lists of numerical values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with statistics (mean, std, 5% quantile, 95% quantile) for each key.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each key-value pair in the dictionary\n",
    "    for key, metrics in data_dict.items():\n",
    "        for metric_name, values in metrics.items():\n",
    "            # Calculate statistics\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values)\n",
    "            quantile_5_val = np.percentile(values, 5)\n",
    "            quantile_95_val = np.percentile(values, 95)\n",
    "\n",
    "            # Append the results as a dictionary\n",
    "            results.append({\n",
    "                key_name: key,\n",
    "                \"metric\": metric_name,\n",
    "                f\"{metric_name}_mean\": mean_val,\n",
    "                f\"{metric_name}_std\": std_val,\n",
    "                f\"{metric_name}_quantile_5\": quantile_5_val,\n",
    "                f\"{metric_name}_quantile_95\": quantile_95_val,\n",
    "            })\n",
    "\n",
    "    # Convert the results into a DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def analysis_scan_orig_geometry(modules, orig_X_Ia):\n",
    "    \"\"\"Analyze the geometry by comparing scan data with the original geometry.\"\"\"\n",
    "    facets_N_OS = define_facets()\n",
    "    aggregated_nodes = {}\n",
    "    aggregated_normals = {}\n",
    "\n",
    "    for module_id, (file_name, axes_angles) in modules.items():\n",
    "        cell = WBScannedCell(file_path=file_name, rotate_system=[axes_angles[0], axes_angles[1]])\n",
    "        tree = initialize_kdtree(cell.O_crease_nodes_X_Na)\n",
    "        distances, scan_indices = compute_nearest_neighbors(tree, orig_X_Ia)\n",
    "        scan_X_Ia = cell.O_crease_nodes_X_Na[scan_indices]\n",
    "\n",
    "        df_nodes = create_differences_dataframe(orig_X_Ia, scan_X_Ia, scan_indices, distances)\n",
    "        save_dataframe_to_excel(df_nodes, f\"WBScanCell_Nodes_Evaluation_{module_id}.xlsx\")\n",
    "\n",
    "        # Calculate normals, angles, and rotation directions\n",
    "        df_normals = calculate_normals_and_angle(facets_N_OS, orig_X_Ia, scan_X_Ia)\n",
    "        save_dataframe_to_excel(df_normals, f\"WBScanCell_Normals_Evaluation_{module_id}.xlsx\")\n",
    "        \n",
    "        # Aggregate index of the crease nodes for statistics\n",
    "        for i in range(len(orig_X_Ia)):\n",
    "            if i not in aggregated_nodes:\n",
    "                aggregated_nodes[i] = {\n",
    "                    'delta_x': [], 'delta_y': [], 'delta_z': [],\n",
    "                    'euclidean_distance': []\n",
    "                }\n",
    "            aggregated_nodes[i]['delta_x'].append(scan_X_Ia[i, 0] - orig_X_Ia[i, 0])\n",
    "            aggregated_nodes[i]['delta_y'].append(scan_X_Ia[i, 1] - orig_X_Ia[i, 1])\n",
    "            aggregated_nodes[i]['delta_z'].append(scan_X_Ia[i, 2] - orig_X_Ia[i, 2])\n",
    "            aggregated_nodes[i]['euclidean_distance'].append(distances[i])\n",
    "            \n",
    "        # Aggregate index of the facets for statistics\n",
    "        for i in range(len(facets_N_OS)):\n",
    "            if i not in aggregated_normals:\n",
    "                aggregated_normals[i] = {\n",
    "                    'angle_between_normals': [] \n",
    "                }\n",
    "            aggregated_normals[i]['angle_between_normals'].append(df_normals.iloc[i, 1])\n",
    "\n",
    "    df_nodes_stats = compute_statistics(aggregated_nodes)\n",
    "    save_dataframe_to_excel(df_nodes_stats, \"WBScanCell_Nodes_Statistics.xlsx\")\n",
    "    \n",
    "    df_normals_stats = calculate_statistics_from_dict(aggregated_normals, key_name=\"facet_index\")\n",
    "    save_dataframe_to_excel(df_normals_stats, \"WBScanCell_Normals_Statistics.xlsx\")\n",
    "\n",
    "    \n",
    "\n",
    "    return cell, scan_X_Ia, df_nodes, df_nodes_stats, df_normals, df_normals_stats\n",
    "\n",
    "cell, scan_X_Ia, df_nodes, df_nodes_stats, df_normals, df_normals_stats = analysis_scan_orig_geometry(modules, orig_X_Ia)\n",
    "df_normals_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_error(node_indices, mean_distances, std_distances, x_label, y_label, legend_label, color_index, plot_name):\n",
    "    \"\"\"\n",
    "    Create a plot with error bars showing the mean and standard deviation of distances.\n",
    "    \n",
    "    Parameters:\n",
    "        node_indices (np.ndarray): Array of node indices.\n",
    "        mean_distances (np.ndarray): Array of mean distances.\n",
    "        std_distances (np.ndarray): Array of standard deviations of distances.\n",
    "    \"\"\"\n",
    "\n",
    "    # Importing necessary libraries\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Define global style settings\n",
    "    rcParams['font.family'] = 'Arial'\n",
    "    rcParams['mathtext.fontset'] = 'stix'  # Use Times font for math\n",
    "    rcParams['mathtext.rm'] = 'Arial'  # Set Times for regular math text\n",
    "\n",
    "    colors = [\n",
    "        '#00549f',  # 0: dark_blue\n",
    "        '#407fb7',  # 1: medium_blue\n",
    "        '#8ebae5',  # 2: light_blue\n",
    "        '#c7ddf2',  # 3: sky_blue\n",
    "        '#e8f1fa',  # 4: very_light_blue\n",
    "        '#57ab27',  # 5: (green)\n",
    "        '#8dc060',  # 6: (light green)\n",
    "        '#b8d698',  # 7: (pale green)\n",
    "        '#ddebce',  # 8: (very pale green)\n",
    "        '#f2f7ec',   # 9: (almost white)\n",
    "        '#cc071e',  # 10: (deep red)\n",
    "        '#d85c41',  # 11: (red orange)\n",
    "        '#e69679',  # 12: (light red orange)\n",
    "        '#f3cdbb',  # 13: (pale red orange)\n",
    "        '#faebe3',  # 14: (very pale red)\n",
    "        \n",
    "    ]\n",
    "    # Set figure size (half A4 width)\n",
    "    fig = plt.figure(figsize=(12 / 2.54, 8 / 2.54))  # Convert cm to inches\n",
    "    ax = plt.gca()  # Get current axis\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    # Plot with error bars\n",
    "    plt.errorbar(\n",
    "        node_indices, mean_distances, yerr=std_distances, \n",
    "        fmt='o', color=colors[color_index], ecolor='black', elinewidth=0.5, capsize=3, label=legend_label\n",
    "    )\n",
    "\n",
    "    # Customize plot\n",
    "    plt.xlabel(x_label, fontsize=12)\n",
    "    plt.ylabel(y_label, fontsize=12)\n",
    "    plt.xticks(node_indices, fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(loc='best', fontsize=8)\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_name+'.png', dpi=300)\n",
    "    plt.savefig(plot_name+'.pdf', dpi=300)\n",
    "    plt.savefig(plot_name+'.svg', dpi=300)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('WBScanCell_Nodes_Statistics.xlsx')\n",
    "# Example data\n",
    "node_indices = df['node_index'].values # Node indices\n",
    "mean_distances = df['mean_distance'].values # Mean distances\n",
    "std_distances = df['std_distance'].values # Standard deviations of distances\n",
    "plot_mean_error(node_indices, mean_distances, std_distances, 'Numbering of the analytical and scanned crease nodes [-]', 'Average distance [mm]', 'Average distance and standard deviation', 5, 'statistical_analysis_nodes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('WBScanCell_Normals_Statistics.xlsx')\n",
    "# Example data\n",
    "node_indices = df['facet_index'].values # Node indices\n",
    "mean_distances = df['angle_between_normals_mean'].values # Mean distances\n",
    "std_distances = df['angle_between_normals_std'].values # Standard deviations of distances\n",
    "plot_mean_error(node_indices, mean_distances, std_distances, 'Numbering of the analytical and scanned facets [-]', \"Average angle between normals [deg]\", 'Average angle and standard deviation', 10, 'statistical_analysis_facets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(name='Vectors')\n",
    "cell.plot_O_crease_lines(plot, line_numbers=False)\n",
    "cell.plot_O_basis(plot)\n",
    "cell.plot_points(plot, orig_X_Ia, point_size=25, color=0x0000ff, plot_numbers=True)\n",
    "cell.plot_points(plot, scan_X_Ia, point_size=25, color=0x007777, plot_numbers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmcs_virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
